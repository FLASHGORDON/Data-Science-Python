{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:15.283110Z",
     "start_time": "2018-07-15T13:57:13.203849Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T04:50:21.854747Z",
     "start_time": "2018-07-16T04:50:21.751978Z"
    }
   },
   "outputs": [],
   "source": [
    "#primary libraries python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#SKlearn and some models\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score,mean_squared_error,precision_score,recall_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,AdaBoostClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#catboost\n",
    "from catboost import CatBoostClassifier as CBC\n",
    "\n",
    "#SMOTE and resampling \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek,SMOTEENN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "#xgboost\n",
    "from xgboost import XGBClassifier as xgbc\n",
    "import xgboost\n",
    "\n",
    "lb = LabelEncoder() \n",
    "plt.rcParams['figure.figsize'] = (20,8)\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.397809Z",
     "start_time": "2018-07-15T13:57:23.292987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_data(locations):\n",
    "    if locations == None:\n",
    "        print('Please enter a valid Location for the data')\n",
    "        return 0\n",
    "    elif str.find(locations,'.csv') >=0:\n",
    "        return pd.read_csv(locations,error_bad_lines=False)\n",
    "        \n",
    "    elif str.find(locations,'.xlsx') >=0:\n",
    "        return pd.read_excel(locations,error_bad_lines= False)\n",
    "    else:\n",
    "        print('Data type not supported')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function to remove nan from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.492461Z",
     "start_time": "2018-07-15T13:57:23.400711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_nan(data, indexes):\n",
    "    for i in indexes:\n",
    "        data.loc[np.isnan(data[i]),i] = np.nanmedian(data[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function to detect numeric data attribute within a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.583549Z",
     "start_time": "2018-07-15T13:57:23.494448Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detect_numerals(data):\n",
    "    num = data.dtypes.index[(data.dtypes == 'int64')| (data.dtypes == 'int32')|(data.dtypes == 'float64')].tolist()\n",
    "    if len(data.isnull().sum()[data.isnull().sum() > 0].index.tolist()) > 0:\n",
    "        indexes = data.isnull().sum()[data.isnull().sum() > 0].index.tolist()\n",
    "        data = remove_nan(data,indexes)\n",
    "    non_num = list()\n",
    "    for i in num:\n",
    "        if np.unique(data[i]).shape[0] <= 10:\n",
    "            non_num.append(i)\n",
    "        \n",
    "    return set(num) - set(non_num),data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function to plot important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.671975Z",
     "start_time": "2018-07-15T13:57:23.586157Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_imp_feat(cols, feat_imp):\n",
    "    '''\n",
    "    col = Column names used to predict the label\n",
    "    feat_imp = Model feature importance data or matrix\n",
    "    This function plots the feature importance of the dataset's attributes.\n",
    "    '''\n",
    "    feat = pd.DataFrame()\n",
    "    feat['features'] = cols\n",
    "    feat['importance'] = feat_imp\n",
    "    feat = feat.sort_values(by = 'importance')\n",
    "    \n",
    "    plt.barh(feat.features,feat.importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Encoding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.761724Z",
     "start_time": "2018-07-15T13:57:23.673925Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert(df, columns):\n",
    "    for i in columns:\n",
    "        df[i] = lb.fit_transform(df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.861421Z",
     "start_time": "2018-07-15T13:57:23.765681Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_submission(ids,preds,col_names,name = 'submission.csv'):\n",
    "    '''\n",
    "    ids = id column of submission dataset\n",
    "    preds = predictions made by the model\n",
    "    col_names = A list of length 2 which consists the column names of submission file\n",
    "    name = Name of the submission file\n",
    "    '''\n",
    "    if len(ids) != len(preds):\n",
    "        raise ValueError('Ids and predictions lengths are not same')\n",
    "        \n",
    "    submission = pd.DataFrame()\n",
    "    submission[col_names[0]] = ids\n",
    "    submission[col_names[1]] = preds\n",
    "\n",
    "    submission.to_csv(f'./{name}', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Function to predict missing values through RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:23.962200Z",
     "start_time": "2018-07-15T13:57:23.862418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rf_classifier(x_train,y_train,x_test,n_est= 500, m_dep = 10):\n",
    "    '''\n",
    "    x_train: training_data\n",
    "    y_train: target \n",
    "    x_test: testing_data\n",
    "    n_est: no. of estimators\n",
    "    m_dep: max_depth\n",
    "    '''\n",
    "    rf = RandomForestClassifier(n_estimators= n_est, max_depth = m_dep,n_jobs = 6,random_state = 42,oob_score=True)\n",
    "    model = rf.fit(x_train,y_train)\n",
    "    print(rf.score(x_train,y_train))\n",
    "    return model.predict(x_test) \n",
    "\n",
    "def pred_missing(df,pred_col, cols,trans_col):\n",
    "    \n",
    "    lb = LabelEncoder()\n",
    "    x_train = df[df[pred_col].notnull()][cols]\n",
    "    x_test = df[df[pred_col].isnull()][cols]\n",
    "    if trans_col != None:\n",
    "        for i in trans_col:\n",
    "            x_train[i] = lb.fit_transform(x_train[i].astype(str))\n",
    "            x_test[i] = lb.fit_transform(x_test[i].astype(str))\n",
    "        \n",
    "    y_train = lb.fit_transform(df[df[pred_col].notnull()][pred_col])\n",
    "    \n",
    "    \n",
    "    return lb.inverse_transform(rf_classifier(x_train,y_train,x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T14:23:08.562931Z",
     "start_time": "2018-07-15T14:23:08.466050Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_smote(x,y,cols):\n",
    "    sm = SMOTEENN(random_state = 42,kind_smote='borderline2',kind_enn = 'mode')\n",
    "    train_x,train_y = sm.fit_sample(x,y)\n",
    "    train_x = pd.DataFrame(train_x,columns=cols)\n",
    "    city_development_index = train_x.city_development_index\n",
    "    train_x = np.round(train_x.drop('city_development_index',1))\n",
    "    train_x['city_development_index'] = city_development_index\n",
    "    \n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:08:17.856768Z",
     "start_time": "2018-07-16T08:08:17.758014Z"
    }
   },
   "outputs": [],
   "source": [
    "def resampling(df,length):\n",
    "    df_majority = df[df.target == 0]\n",
    "    df_minority = df[df.target == 1]\n",
    "    \n",
    "    df_minority_upsampled = resample(df_minority,\n",
    "                                    replace = True,\n",
    "                                    n_samples = length,\n",
    "                                    random_state = 123)\n",
    "    df_majority = resample(df_majority,\n",
    "                          replace = True,\n",
    "                          n_samples = 2*length)\n",
    "    \n",
    "    df_upscaled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    \n",
    "    return df_upscaled.drop('target',1),df_upscaled.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to predict on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:08:46.379139Z",
     "start_time": "2018-07-16T08:08:46.281172Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_val(df,target,clf,test_size = 0.2,smote = False,resample = False,length = 10000):\n",
    "    train_x,valid_x, train_y, valid_y = train_test_split(df,target,test_size = test_size,random_state = 42,shuffle = True)\n",
    "    \n",
    "    if smote == True:\n",
    "        train_x,train_y = apply_smote(train_x,train_y, valid_x.columns)\n",
    "        valid_x.columns = train_x.columns\n",
    "    elif resample == True:\n",
    "        combined_df = train_x.copy()\n",
    "        combined_df['target'] = train_y\n",
    "        train_x,train_y= resampling(combined_df,length)\n",
    "    \n",
    "    model = clf.fit(train_x,train_y)\n",
    "    y_preds = model.predict(valid_x)\n",
    "        \n",
    "    return valid_y, y_preds,model,train_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to predict on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T04:15:48.789582Z",
     "start_time": "2018-07-16T04:15:48.691843Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_test(train,target,test,clf,smote = False,resample = False):\n",
    "    if smote == True:\n",
    "        train,target = apply_smote(train,target,test.columns)\n",
    "        test.columns = train.columns\n",
    "    elif resample == True:\n",
    "        combined_df = train.copy()\n",
    "        combined_df['target'] = target\n",
    "        train,target = resampling(combined_df)\n",
    "        test.columns = train.columns\n",
    "        \n",
    "    model = clf.fit(train,target)\n",
    "    y_preds = model.predict(test)\n",
    "    return y_preds,model,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:24.817381Z",
     "start_time": "2018-07-15T13:57:24.148409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_set = read_data('./Datasets/Analytics Vidhya Datafest Supremacy/train.csv')\n",
    "test_set = read_data('./Datasets/Analytics Vidhya Datafest Supremacy/test.csv')\n",
    "\n",
    "train_set.columns= ['enrollee_id', 'city', 'city_development_index', 'gender',\n",
    "       'relevent_experience', 'enrolled_university', 'enrolled_university_1',\n",
    "       'major_discipline', 'experience', 'company_size', 'company_type',\n",
    "       'last_new_job', 'training_hours', 'target']\n",
    "test_set.columns = ['enrollee_id', 'city', 'city_development_index', 'gender',\n",
    "       'relevent_experience', 'enrolled_university', 'enrolled_university_1',\n",
    "       'major_discipline', 'experience', 'company_size', 'company_type',\n",
    "       'last_new_job', 'training_hours']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Converting exp and last_job to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:24.949089Z",
     "start_time": "2018-07-15T13:57:24.819351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert experience to numeric\n",
    "train_set.loc[train_set.experience == '>20', 'experience'] = '21'\n",
    "train_set.loc[train_set.experience == '<1', 'experience'] = '0'\n",
    "train_set.experience = pd.to_numeric(train_set.experience)\n",
    "\n",
    "test_set.loc[test_set.experience == '>20', 'experience'] = '21'\n",
    "test_set.loc[test_set.experience == '<1', 'experience'] = '0'\n",
    "test_set.experience = pd.to_numeric(test_set.experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.043951Z",
     "start_time": "2018-07-15T13:57:24.950085Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_set.loc[train_set.experience.isnull(), 'experience'] = int(np.nanmean(train_set.experience))\n",
    "test_set.loc[test_set.experience.isnull(), 'experience'] = int(np.nanmean(test_set.experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.166668Z",
     "start_time": "2018-07-15T13:57:25.044949Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert last_new_job to numeric\n",
    "train_set.loc[train_set.last_new_job == '>4', 'last_new_job'] = '5'\n",
    "train_set.loc[train_set.last_new_job == 'never', 'last_new_job'] = '0'\n",
    "train_set.last_new_job = pd.to_numeric(train_set.last_new_job)\n",
    "\n",
    "\n",
    "test_set.loc[test_set.last_new_job == '>4', 'last_new_job'] = '5'\n",
    "test_set.loc[test_set.last_new_job == 'never', 'last_new_job'] = '0'\n",
    "test_set.last_new_job = pd.to_numeric(test_set.last_new_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Consider missing values as another category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.270367Z",
     "start_time": "2018-07-15T13:57:25.168645Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def new_value(df,cols):\n",
    "    for i in cols:\n",
    "        df.loc[df[i].isnull(), i] = 'not null'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.371068Z",
     "start_time": "2018-07-15T13:57:25.271327Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_temp = train_set.copy()\n",
    "test_temp = test_set.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.486556Z",
     "start_time": "2018-07-15T13:57:25.372968Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['gender','major_discipline','company_size','company_type']\n",
    "train_temp = new_value(train_temp,cols)\n",
    "test_temp = new_value(test_temp,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.594019Z",
     "start_time": "2018-07-15T13:57:25.488741Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imputing missing value for last_new_job\n",
    "exp_median = [np.median(train_temp[(train_temp.last_new_job.notnull()) & (train_temp.last_new_job == i)].experience) \n",
    "              for i in np.sort(train_temp.last_new_job.unique()[:-1])]\n",
    "train_temp.loc[train_temp.last_new_job.isnull() , 'last_new_job'] = 1\n",
    "test_temp.loc[test_temp.last_new_job.isnull() , 'last_new_job'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:25.688502Z",
     "start_time": "2018-07-15T13:57:25.595751Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_temp = train_temp[(train_temp.enrolled_university.notnull()) & (train_temp.enrolled_university_1.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:30.510855Z",
     "start_time": "2018-07-15T13:57:25.690498Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169854836521503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814576781074798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "col_for_en_u = ['city_development_index','experience','last_new_job','relevent_experience','company_type','company_size']\n",
    "cat_cols = ['relevent_experience','company_type','company_size']\n",
    "\n",
    "# train_temp.loc[train_temp.enrolled_university.isnull(), 'enrolled_university'] = pred_missing(train_temp,\n",
    "#                                                                                               'enrolled_university',\n",
    "#                                                                                               col_for_en_u,\n",
    "#                                                                                               cat_cols)\n",
    "\n",
    "test_temp.loc[test_temp.enrolled_university.isnull(), 'enrolled_university'] = pred_missing(test_temp,\n",
    "                                                                                              'enrolled_university',\n",
    "                                                                                              col_for_en_u,\n",
    "                                                                                              cat_cols)\n",
    "# train_temp.loc[train_temp.enrolled_university_1.isnull(), 'enrolled_university_1'] = pred_missing(train_temp,\n",
    "#                                                                                               'enrolled_university_1',\n",
    "#                                                                                               col_for_en_u,\n",
    "#                                                                                               cat_cols)\n",
    "\n",
    "test_temp.loc[test_temp.enrolled_university_1.isnull(), 'enrolled_university_1'] = pred_missing(test_temp,\n",
    "                                                                                              'enrolled_university_1',\n",
    "                                                                                              col_for_en_u,\n",
    "                                                                                              cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:30.741239Z",
     "start_time": "2018-07-15T13:57:30.511852Z"
    }
   },
   "outputs": [],
   "source": [
    "converted_train = convert(train_temp,['city', 'gender', 'relevent_experience',\n",
    "       'enrolled_university', 'enrolled_university_1', 'major_discipline',\n",
    "        'company_size', 'company_type'])\n",
    "converted_test = convert(test_temp,['city', 'gender', 'relevent_experience',\n",
    "       'enrolled_university', 'enrolled_university_1', 'major_discipline',\n",
    "        'company_size', 'company_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost\n",
    "\n",
    "* We're getting roc_auc_score of 0.50 on stock data with missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:11:57.713158Z",
     "start_time": "2018-07-16T08:11:57.566134Z"
    }
   },
   "outputs": [],
   "source": [
    "xgboostmodel = xgbc(random_state= 42, n_jobs=6,scale_pos_weight=7,subsample = 0.8,eta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:11:58.414811Z",
     "start_time": "2018-07-16T08:11:57.790591Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6391170207353679"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_preds,model,train = predict_val(converted_train.drop(['enrollee_id','target','enrolled_university_1'],1),\n",
    "                              converted_train.target,xgboostmodel)\n",
    "\n",
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:31.411293Z",
     "start_time": "2018-07-15T13:57:31.063377Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_imp_feat(converted_train.drop(['enrollee_id','target'],1).columns,model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:10:56.154786Z",
     "start_time": "2018-07-16T08:10:55.337428Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_preds,model,_ = predict_test(converted_train.drop(['enrollee_id','target'],1),\n",
    "                              converted_train.target,\n",
    "                               converted_test.drop(['enrollee_id'],1),\n",
    "                               xgboostmodel)\n",
    "make_submission(converted_test.enrollee_id,y_preds,['enrollee_id','target'],'submission_supermacy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:52:28.952882Z",
     "start_time": "2018-07-16T07:52:28.824226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_jobs= 6,random_state=42,class_weight={0:1,1:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:52:29.442198Z",
     "start_time": "2018-07-16T07:52:29.057307Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5190724684027298"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_preds,model,_ = predict_val(converted_train.drop(['enrollee_id','target','enrolled_university_1'],1),\n",
    "                              converted_train.target,rfmodel)\n",
    "\n",
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost\n",
    "\n",
    "* Getting .50 on stock data with missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:38:50.758029Z",
     "start_time": "2018-07-16T07:38:09.816169Z"
    }
   },
   "outputs": [],
   "source": [
    "catboostmodel = CBC(random_state=42,verbose = False,thread_count = 6,scale_pos_weight=6,\n",
    "                    iterations=2000,\n",
    "                    learning_rate=0.01,depth = 4)\n",
    "\n",
    "y_true, y_preds, model,_ = predict_val(converted_train.drop(['enrollee_id','target'],1),\n",
    "                                    converted_train.target, catboostmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:38:50.887457Z",
     "start_time": "2018-07-16T07:38:50.760838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284582567173724"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:57:54.602788Z",
     "start_time": "2018-07-15T13:57:54.386482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logisticregressionmodel = LogisticRegression()\n",
    "y_true, y_preds, model = predict_val(converted_train.drop(['enrollee_id','target'],1),\n",
    "                                    converted_train.target, logisticregressionmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T13:58:34.523483Z",
     "start_time": "2018-07-15T13:58:34.428738Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Applying Oversampling (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T14:23:57.479845Z",
     "start_time": "2018-07-15T14:23:56.709064Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\deprecation.py:50: DeprecationWarning: 'k' is deprecated from 0.2 and will be removed in 0.4. Use 'k_neighbors' instead.\n",
      "  category=DeprecationWarning)\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\deprecation.py:50: DeprecationWarning: 'm' is deprecated from 0.2 and will be removed in 0.4. Use 'm_neighbors' instead.\n",
      "  category=DeprecationWarning)\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5293965448321474"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true,y_preds, model,_ = predict_val(converted_train.drop(['enrollee_id','target'],1),\n",
    "                                    converted_train.target,xgboostmodel,0.2, True)\n",
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T14:23:52.821909Z",
     "start_time": "2018-07-15T14:23:26.458558Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\deprecation.py:50: DeprecationWarning: 'k' is deprecated from 0.2 and will be removed in 0.4. Use 'k_neighbors' instead.\n",
      "  category=DeprecationWarning)\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\deprecation.py:50: DeprecationWarning: 'm' is deprecated from 0.2 and will be removed in 0.4. Use 'm_neighbors' instead.\n",
      "  category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5024721820467908"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true,y_preds, model,train_x = predict_val(converted_train.drop(['enrollee_id','target'],1),\n",
    "                                    converted_train.target,catboostmodel,0.2, True)\n",
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:03:27.022245Z",
     "start_time": "2018-07-16T08:03:26.924506Z"
    }
   },
   "outputs": [],
   "source": [
    "train_new = converted_train.copy()\n",
    "test_new = converted_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:03:27.870335Z",
     "start_time": "2018-07-16T08:03:27.159232Z"
    }
   },
   "outputs": [],
   "source": [
    "train_new['dev_ind_range'] = pd.cut(train_new.city_development_index,bins= 30)\n",
    "train_new['training_hours_range'] = pd.cut(train_new.training_hours, bins = 40)\n",
    "train_new = convert(train_new,['dev_ind_range','training_hours_range'])\n",
    "\n",
    "test_new['dev_ind_range'] = pd.cut(test_new.city_development_index,bins = 30)\n",
    "test_new['training_hours_range'] = pd.cut(test_new.training_hours, bins = 40)\n",
    "test_new = convert(test_new, ['dev_ind_range','training_hours_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:03:27.972309Z",
     "start_time": "2018-07-16T08:03:27.871331Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_city(df):\n",
    "    city_pop = pd.DataFrame()\n",
    "    city_pop['city'] = df.city.unique()\n",
    "    city_pop['city_population'] = [len(df[df.city == i]) for i in df.city.unique()]\n",
    "    city_pop['avg_experience'] = [np.median(df[df.city == i].experience) for i in df.city.unique()]\n",
    "    city_pop['avg_training_hours'] = [(np.median(df[df.city == i].training_hours)) for i in df.city.unique()]\n",
    "    df = df.merge(city_pop, on= 'city', how = 'inner')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:03:28.563774Z",
     "start_time": "2018-07-16T08:03:27.975068Z"
    }
   },
   "outputs": [],
   "source": [
    "train_new = new_city(train_new)\n",
    "test_new = new_city(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:05:22.924686Z",
     "start_time": "2018-07-16T08:05:22.586592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6433348161843926"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmodel = xgbc(random_state = 42, n_jobs = 6,scale_pos_weight=8,subsample = 0.95)\n",
    "\n",
    "y_true,y_preds, model, _ = predict_val(train_new.drop(['enrollee_id','target'],1),\n",
    "                                      train_new.target,xgbmodel)\n",
    "roc_auc_score(y_true,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:06:34.638001Z",
     "start_time": "2018-07-16T08:06:34.203166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_preds,model,_ = predict_test(train_new.drop(['enrollee_id','target'],1),\n",
    "                              train_new.target,\n",
    "                               test_new.drop(['enrollee_id'],1),\n",
    "                               xgbmodel)\n",
    "\n",
    "make_submission(converted_test.enrollee_id,y_preds,['enrollee_id','target'],'submission_supermacy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T08:06:35.376720Z",
     "start_time": "2018-07-16T08:06:35.278977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8389\n",
       "1    6632\n",
       "dtype: int64"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T07:30:49.169917Z",
     "start_time": "2018-07-16T07:30:48.965383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predictions</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1496</td>\n",
       "      <td>1113</td>\n",
       "      <td>2609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213</td>\n",
       "      <td>183</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1709</td>\n",
       "      <td>1296</td>\n",
       "      <td>3005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predictions     0     1   All\n",
       "Actual                       \n",
       "0            1496  1113  2609\n",
       "1             213   183   396\n",
       "All          1709  1296  3005"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    pd.Series(y_true, name = 'Actual'),\n",
    "    pd.Series(y_preds, name = 'Predictions'),\n",
    "    margins = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
