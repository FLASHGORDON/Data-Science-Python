{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from functools import partial\n",
    "from fastai.vision import *\n",
    "import fastai.vision\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from torchvision.models import *\n",
    "import pretrainedmodels\n",
    "\n",
    "from fastai.vision.models import *\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.vision.gan import GANLearner\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../Data/game_of_deep_learning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = pd.read_csv(os.path.join(PATH,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2120\n",
       "5    1217\n",
       "2    1167\n",
       "3     916\n",
       "4     832\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of images per category\n",
    "train_files.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transform Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 320\n",
    "batch_size = 20\n",
    "\n",
    "xtra_tfm = [\n",
    "    brightness(change=[0.3, 0.5]),\n",
    "    contrast(scale=[1.5, 0.5]),\n",
    "    perspective_warp(magnitude=[0.5, 0.7])\n",
    "]\n",
    "\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfm)\n",
    "\n",
    "train_data = (ImageList.from_csv(\n",
    "    path_img, 'train.csv', folder='images',\n",
    "    cols='image').split_none().label_from_df(cols='category').transform(\n",
    "        tfms, size=img_size, resize_method=ResizeMethod.SQUISH).databunch(\n",
    "            bs=batch_size).normalize(imagenet_stats))\n",
    "\n",
    "test_data = ImageList.from_csv(path_img, 'test_ApKoW4T.csv', folder='images')\n",
    "\n",
    "train_data.add_test(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Image.open(os.path.join('../data/train/images',train_files.image[9]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data.train_ds[8][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResneXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnext101_32(pretrained = False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.resnext101_64x4d(pretrained = pretrained)\n",
    "    all_layers = list(model.children())\n",
    "    return nn.Sequential(*all_layers[0], *all_layers[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(pretrained = False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext101_32x4d(pretrained = pretrained)\n",
    "    all_layers = list(model.children())\n",
    "    return nn.Sequential(*all_layers[0], *all_layers[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nas_net(pretrained = False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.nasnetalarge(num_classes = 1000,pretrained = pretrained)\n",
    "    all_layers = list(model.children())\n",
    "    return nn.Sequential(*all_layers[0], *all_layers[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = cnn_learner(train_data, nas_net, pretrained = True,\n",
    "#                   cut = -2, split_on = lambda m:(m[0][6],m[1]))\n",
    "learn = cnn_learner(train_data, nas_net, pretrained = True,cut = -2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def _densenet_split(m:nn.Module): return (m[0][0][7], m[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn = cnn_learner(train_data, densenet201,\n",
    "                   cut = -1, split_on = _densenet_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.show_batch(rows = 3, figsize = (10,10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn = cnn_learner(train_data, models.resnet152)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr = 1e-3\n",
    "lrs = np.array([lr/9,lr/3,lr])\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, lrs, div_factor=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.freeze()\n",
    "learn.fit_one_cycle(25,max_lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnext101_game_of_deep_learning_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionv4(pretrained = False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.inceptionv4(pretrained = pretrained)\n",
    "    all_layers = list(model.children())\n",
    "    return nn.Sequential(*all_layers[0], *all_layers[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(train_data,inceptionv4,pretrained = True,\n",
    "                   cut=-2, split_on = lambda m:(m[0][11], m[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10,max_lr = (1e-3,1e-2,1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.show_results(rows = 3, figsize = (12,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(15,figsize = (15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds, valid_labels = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = np.argmax(valid_preds,1)\n",
    "print(f1_score(valid_labels, valid_preds,average= 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SMRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from smrt.autoencode import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "lr = 1e-3\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "channels = 3\n",
    "sample_interval = 400\n",
    "n_epochs = 200\n",
    "nz = latent_dim\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_files[train_files.category == 5].reset_index(drop = True).to_csv('./category_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class deep_learning_data(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform = None,y=True):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.files = pd.read_csv(csv_file)\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                               self.files.iloc[idx,0])\n",
    "        image = Image.fromarray(cv2.imread(img_name))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if (np.array(image.size()) == np.array([1,img_size,img_size])).all():\n",
    "            print(img_name)\n",
    "\n",
    "        return (image, self.files.iloc[idx,1]-1)\n",
    "        \n",
    "img_transforms = {\n",
    "    'train': \n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size =(img_size,img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]),\n",
    "    \n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(img_size,img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "train_dataset= deep_learning_data(csv_file = './category_5.csv',\n",
    "                                 root_dir = '../data/train/images',\n",
    "                                 transform = img_transforms['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf,nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(1)\n",
    "discriminator = Discriminator(1)\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset,batch_size = batch_size,\n",
    "                       shuffle = True, num_workers = 4)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "criterion = nn.BCELoss()\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "fixed_noise = torch.randn(batch_size, nz, 1,1,device =device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output.shape,label.shape,real_cpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = tqdm_notebook(range(n_epochs))\n",
    "\n",
    "for epoch in t:\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        discriminator.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = discriminator(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = generator(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        generator.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, opt.niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    '%s/real_samples.png' % opt.outf,\n",
    "                    normalize=True)\n",
    "            fake = generator(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "                    normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr= 0.001, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "val_acc_history = []\n",
    "\n",
    "# best_model_wts = copy.deepcopy(model.cpu().state_dict())\n",
    "\n",
    "best_acc = 0.0\n",
    "t = tqdm.tqdm_notebook(range(n_epochs))\n",
    "k = tqdm.tqdm_notebook(train_dataloader)\n",
    "for epoch in t:\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in k:\n",
    "#             pdb.set_trace()\n",
    "#             print(inputs.shape)\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs,1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
    "    \n",
    "    print('{} Loss : {:.4f} Acc: {:.4f}'.format('Train',epoch_loss,epoch_acc))\n",
    "\n",
    "# model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0],labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds,_ = learn.TTA(ds_type = DatasetType.Test)\n",
    "\n",
    "preds = np.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv('../Data/game_of_deep_learning/test_ApKoW4T.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.loc[:,'category'] = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.to_csv('submission_9.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
