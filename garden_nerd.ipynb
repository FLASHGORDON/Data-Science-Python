{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "We are given a large class of flowers, 102 to be precise. Build a flower classification model which is discriminative between classes but can correctly classify all flower images belonging to the same class. There are a total of 20549 (train + test) images of flowers. Predict the category of the flowers present in the test folder with good accuracy.\n",
    "\n",
    "### Guidelines\n",
    "\n",
    "* Your output will be evaluated only for 50% of the test data while the contest is running. Once the contest is over, output for the remaining 50% of the data will be evaluated and the final rank will be awarded.\n",
    "* You will have to upload your output on the problem page in the format given in the problem statement. In addition to your output, you will also have to submit your source and other files in .zip or .tar compressed archive.\n",
    "* The total number of submission allowed by a participant is 40. The maximum number of submission a participant can make in a day is five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.transforms.functional as functional\n",
    "from skimage import io, transform\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pdb,tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(filename):\n",
    "    img = mpimg.imread('../data/train/images/'+filename)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "test_files = pd.read_csv(os.path.join(path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Data Loader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:15:23.781763Z",
     "start_time": "2019-05-27T17:15:23.775606Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class deep_learning_data(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, y=True):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.files = pd.read_csv(csv_file)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                str(self.files.iloc[idx, 0]) + '.jpg')\n",
    "        image = Image.fromarray(cv2.imread(img_name))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if (np.array(image.size()) == np.array([1, 224, 224])).all():\n",
    "            print(img_name)\n",
    "\n",
    "        return (image, self.files.iloc[idx, 1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:15.758328Z",
     "start_time": "2019-05-27T17:26:15.752873Z"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        #         transforms.RandomResizedCrop(size = 256, scale=(0.8,1.0)),\n",
    "        #         transforms.RandomRotation(degrees = 15),\n",
    "        #         transforms.ColorJitter(),\n",
    "        #         transforms.RandomHorizontalFlip(),\n",
    "        #         transforms.CenterCrop(size = 224),\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        #         transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]),\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        #         transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:16.526616Z",
     "start_time": "2019-05-27T17:26:16.511158Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = deep_learning_data(csv_file=os.path.join(path, 'train.csv'),\n",
    "                                   root_dir=os.path.join(path, 'train'),\n",
    "                                   transform=img_transforms['train'])\n",
    "# test_dataset = deep_learning_data(csv_file = '../data/test_ApKoW4T.csv',\n",
    "#                                  root_dir = '../data/train/images',\n",
    "#                                  transform = img_transforms['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:16.702375Z",
     "start_time": "2019-05-27T17:26:16.699402Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=12,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:26.981849Z",
     "start_time": "2019-05-27T17:26:26.568447Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "# inputs contains 4 images because batch_size=4 for the dataloaders\n",
    "inputs, classes = next(iter(train_dataloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "plt.figure(figsize=[20, 10])\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning - Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:26.988054Z",
     "start_time": "2019-05-27T17:26:26.984878Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:27:19.351602Z",
     "start_time": "2019-05-27T17:27:18.509919Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "model = models.resnet101(pretrained=False)\n",
    "set_parameter_requires_grad(model, True)\n",
    "num_feats = model.fc.in_features\n",
    "model.fc = nn.Linear(num_feats, num_classes)\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.resnet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:48.720463Z",
     "start_time": "2019-05-27T17:26:48.713707Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_to_update = model.parameters()\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print('\\t', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:49.836369Z",
     "start_time": "2019-05-27T17:26:49.832602Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(params_to_update, lr= 0.001, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T17:26:52.096297Z",
     "start_time": "2019-05-27T17:26:51.569150Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "val_acc_history = []\n",
    "\n",
    "best_acc = 0.0\n",
    "t = tqdm.tqdm_notebook(range(n_epochs))\n",
    "k = tqdm.tqdm_notebook(train_dataloader)\n",
    "for epoch in t:\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in k:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
    "\n",
    "    print('{} Loss : {:.4f} Acc: {:.4f}'.format('Train', epoch_loss,\n",
    "                                                epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast AI Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from functools import partial\n",
    "from fastai.vision import *\n",
    "import fastai.vision\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from torchvision.models import *\n",
    "import pretrainedmodels\n",
    "\n",
    "from fastai.vision.models import *\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.vision.gan import GANLearner\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 20\n",
    "\n",
    "xtra_tfm = [\n",
    "    brightness(change=[0.3, 0.5]),\n",
    "    contrast(scale=[1.5, 0.5]),\n",
    "    perspective_warp(magnitude=[0.5, 0.7])\n",
    "]\n",
    "\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfm)\n",
    "\n",
    "train_data = (ImageList.from_csv(path, 'train_1.csv', folder='train',cols='image_id')\n",
    "              .split_none()\n",
    "              .label_from_df(cols='category')\n",
    "              .transform(tfms, size=img_size, resize_method=ResizeMethod.SQUISH)\n",
    "              .databunch(bs=batch_size)\n",
    "              .normalize(imagenet_stats))\n",
    "\n",
    "test_data = ImageList.from_csv(path, 'test_1.csv', folder='test')\n",
    "\n",
    "train_data.add_test(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(train_data, models.resnet101, pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(25, max_lr = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,_ = learn.TTA(ds_type = DatasetType.Test)\n",
    "\n",
    "preds = np.argmax(preds,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
